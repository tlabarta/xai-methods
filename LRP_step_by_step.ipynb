{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.124543Z",
     "start_time": "2023-08-10T09:10:40.963178Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Neural Network Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very simple step by step demonstration of Layer-wise relevance propagation (LRP) (Montavon, G., Binder, A., Lapuschkin, S., Samek, W., & MÃ¼ller, K. R. (2019). Layer-wise relevance propagation: an overview. Explainable AI: interpreting, explaining and visualizing deep learning, 193-209).\n",
    "\n",
    "We start by defining a very simple Neural Network with 3 layers for a binary classification task (Is it class 1 or is it class 2?).\n",
    "\n",
    "1. Input Layer: Layer of the network with 3 neurons\n",
    "2. Hidden Layer: Layer with 3 neurons, ReLU activation function\n",
    "3. Output Layer: Layer with 1 neuron, Sigmoid Activation Function, returns probability p for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.128539Z",
     "start_time": "2023-08-10T09:10:41.127150Z"
    }
   },
   "outputs": [],
   "source": [
    "w_hidden = np.asarray([[0.3, 0.2, 0.4],\n",
    "            [0.6, 0.1, 0.5],\n",
    "            [0.8, 0.6, 0.2]])\n",
    "\n",
    "w_output = np.asarray([[0.3],\n",
    "            [0.1],\n",
    "            [0.4]])\n",
    "\n",
    "b_hidden = np.asarray([0.5])\n",
    "\n",
    "b_output = np.asarray([0.1])\n",
    "\n",
    "input = np.asarray([[1.0], [0.8], [0.2]])\n",
    "\n",
    "def ReLU(Z):\n",
    "    A = np.maximum(0, Z)\n",
    "    return A\n",
    "\n",
    "def Sigmoid(Z):\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Initial State](step_by_step_img/initial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Forward Pass to calculate Relevance Score\n",
    "\n",
    "First step is a forward pass to calculate the Relevance score, which equals the activation of the output layer. Forward pass in neural networks is a dot-product of input values and weights plus a bias. We will perform two passes, one from Input to Hidden layer and one from Hidden to Output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.131860Z",
     "start_time": "2023-08-10T09:10:41.130132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.04]\n",
      " [1.28]\n",
      " [1.82]]\n"
     ]
    }
   ],
   "source": [
    "input_hidden = np.dot(w_hidden, input) + b_hidden\n",
    "print(input_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Initial State](step_by_step_img/first_pass.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing the dot product, an activation function is applied. In this case the Rectified Linear Unit (see bottom of Hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.137141Z",
     "start_time": "2023-08-10T09:10:41.135174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.04]\n",
      " [1.28]\n",
      " [1.82]]\n"
     ]
    }
   ],
   "source": [
    "output_hidden = ReLU(input_hidden)\n",
    "print(output_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Initial State](step_by_step_img/first_activation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.140408Z",
     "start_time": "2023-08-10T09:10:41.138125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.268]]\n"
     ]
    }
   ],
   "source": [
    "input_output = np.dot(w_output.T, output_hidden) + b_output\n",
    "print(input_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Initial State](step_by_step_img/second_pass.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.143600Z",
     "start_time": "2023-08-10T09:10:41.141082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78]]\n"
     ]
    }
   ],
   "source": [
    "output_output = Sigmoid(input_output)\n",
    "print(np.round(output_output, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid activation returns a result of 0.78 for the first forward pass, which indicates a 78% probability for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Initial State](step_by_step_img/forwardpass_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculating Relevance scores\n",
    "\n",
    "After the forward pass, we calculate the relevance scores of each neuron layer-for-layer with the formula given in the paper (see below). The sum over the relevance should be equal for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.190325Z",
     "start_time": "2023-08-10T09:10:41.143915Z"
    }
   },
   "outputs": [],
   "source": [
    "relevance = output_output\n",
    "activation_previous = output_hidden\n",
    "activation_sum = np.sum(activation_previous)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.200626Z",
     "start_time": "2023-08-10T09:10:41.146495Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden_relevance = np.round(activation_previous * relevance / activation_sum,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.201345Z",
     "start_time": "2023-08-10T09:10:41.149946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 ]\n",
      " [0.24]\n",
      " [0.34]]\n"
     ]
    }
   ],
   "source": [
    "print(hidden_relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Initial State](step_by_step_img/first_relevance_propagation.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.201517Z",
     "start_time": "2023-08-10T09:10:41.155268Z"
    }
   },
   "outputs": [],
   "source": [
    "relevance = hidden_relevance\n",
    "activation_previous = input\n",
    "activation_sum = np.sum(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.201604Z",
     "start_time": "2023-08-10T09:10:41.157308Z"
    }
   },
   "outputs": [],
   "source": [
    "input_relevance = []\n",
    "for i in range(len(activation_previous)):\n",
    "    input_relevance.append(sum(np.round(relevance * activation_previous[i]  / activation_sum,2)))\n",
    "\n",
    "input_relevance = np.asarray(input_relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:10:41.201712Z",
     "start_time": "2023-08-10T09:10:41.159181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39]\n",
      " [0.32]\n",
      " [0.07]]\n"
     ]
    }
   ],
   "source": [
    "print(input_relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Initial State](step_by_step_img/second_relevance_propagation.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The final relevance scores of the input neurons are: 1. 0.39, 2. 0.32, and 3. 0.07. The scores show a strong relevance of the first and second input on the classification result."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
